{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workflow: From Business Problem to Production\n",
    "## A 60-Minute Introduction to the ML Engineering Process\n",
    "\n",
    "In this lab, we'll walk through the essential steps of developing and deploying a machine learning model. By the end, you'll understand the full lifecycle of a machine learning project and have built a working classification model similar to how our fraud detection system operates.\n",
    "\n",
    "**Agenda:**\n",
    "1. Business Problem Definition (5 min)\n",
    "2. Technical Framing (5 min)\n",
    "3. Data Engineering & Exploration (15 min)\n",
    "4. Model Development & Feature Engineering (15 min)\n",
    "5. Model Validation (10 min) \n",
    "6. Production Deployment Concepts (5 min)\n",
    "7. Ongoing Monitoring Strategies (5 min)\n",
    "\n",
    "Let's get started by setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "# Uncomment if needed\n",
    "# !pip install numpy pandas matplotlib seaborn scikit-learn shap lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, confusion_matrix, classification_report,\n",
    "                             roc_curve, precision_recall_curve)\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "# Set plot styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Problem Definition (5 min)\n",
    "\n",
    "Before writing any code, we need to clearly understand the business problem we're trying to solve. In real-world scenarios, this often involves discussions with stakeholders to define:\n",
    "\n",
    "- What is the business need?\n",
    "- What are the key outcomes we want to improve?\n",
    "- How will success be measured?\n",
    "- What are the constraints and requirements?\n",
    "\n",
    "### Example: Credit Card Fraud Detection\n",
    "\n",
    "For this lab, we'll use a simplified example related to credit card transactions:\n",
    "\n",
    "**Business Problem:** A financial institution is experiencing losses due to fraudulent credit card transactions. They need a system to identify potentially fraudulent transactions before they're completed.\n",
    "\n",
    "**Key Outcomes:**\n",
    "- Reduce financial losses from fraud\n",
    "- Minimize disruption to legitimate customers\n",
    "- Process decisions quickly (under 200ms)\n",
    "\n",
    "**Success Metrics:**\n",
    "- Fraud detection rate (recall) > 85%\n",
    "- False positive rate < 3% (to avoid frustrating legitimate customers)\n",
    "- Decision latency < 200ms per transaction\n",
    "\n",
    "**Constraints:**\n",
    "- Solutions must work with existing transaction processing systems\n",
    "- Must handle ~5000 transactions per minute at peak\n",
    "- Model updates need approval through risk management\n",
    "\n",
    "In our real fraud model, these considerations are more complex, but this gives us a starting point for our lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Technical Framing (5 min)\n",
    "\n",
    "Now we need to translate our business problem into a specific machine learning task. This involves defining:\n",
    "\n",
    "- What type of ML problem is this? (classification, regression, clustering, etc.)\n",
    "- What's our target variable?\n",
    "- What data will be available at prediction time?\n",
    "- How should we frame our evaluation metrics?\n",
    "\n",
    "### Our Technical Framing\n",
    "\n",
    "**ML Problem Type:** Binary Classification (fraud vs. non-fraud)\n",
    "\n",
    "**Target Variable:** Is the transaction fraudulent? (1 = fraud, 0 = legitimate)\n",
    "\n",
    "**Features Available at Prediction Time:**\n",
    "- Transaction details (amount, location, etc.)\n",
    "- Historical patterns (frequency, typical amounts, etc.)\n",
    "- Device information\n",
    "- etc.\n",
    "\n",
    "**Evaluation Framework:**\n",
    "- Primary metric: Recall (catching as many fraud cases as possible)\n",
    "- Secondary metric: Precision (minimizing false alarms)\n",
    "- Balanced metric: Area Under ROC Curve (AUC) for overall model quality\n",
    "\n",
    "**Special Considerations:**\n",
    "- The data is highly imbalanced (fraud is rare)\n",
    "- False negatives (missed fraud) are costly\n",
    "- False positives create customer friction\n",
    "\n",
    "For our lab, we'll use a credit card dataset from scikit-learn to simulate this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Engineering & Exploration (15 min)\n",
    "\n",
    "Now let's get our data and start exploring it. This phase helps us understand the data we're working with and identify potential issues before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# For this lab, we'll use a built-in dataset from scikit-learn\n",
    "# Let's load the breast cancer dataset and treat it as our \"credit card transactions\"\n",
    "# In this analogy, malignant tumors (1) will represent fraudulent transactions\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# In this dataset, 0 is malignant (our \"fraud\") and 1 is benign (\"legitimate\")\n",
    "# Let's invert this to match our domain (1 for fraud, 0 for legitimate)\n",
    "y = 1 - y\n",
    "\n",
    "# Display information about our dataset\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of transactions: {X.shape[0]}\")\n",
    "print(f\"Percentage of fraudulent transactions: {y.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Quality Assessment\n",
    "\n",
    "Before diving into modeling, we need to understand the quality of our data. Here are some key checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "missing_values = X.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0] if missing_values.any() > 0 else \"No missing values\")\n",
    "\n",
    "# Check for duplicate transactions\n",
    "duplicates = X.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicates}\")\n",
    "\n",
    "# Summary statistics of our features\n",
    "print(\"\\nFeature summary statistics:\")\n",
    "X.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Let's examine the class imbalance more closely\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(x=y)\n",
    "plt.title('Distribution of Transactions (Fraud vs Legitimate)')\n",
    "plt.xlabel('Transaction Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Legitimate (0)', 'Fraud (1)'])\n",
    "\n",
    "# Add count and percentage labels\n",
    "total = len(y)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width()/2.,\n",
    "            height + 5,\n",
    "            f'{height} ({height/total:.1%})',\n",
    "            ha=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Exploration\n",
    "\n",
    "Let's explore some of our features to understand their relationships and potential predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Rename columns to simulate transaction data for easier understanding\n",
    "# This mapping is arbitrary but helps conceptualize our dataset as transaction data\n",
    "column_mapping = {\n",
    "    'mean radius': 'transaction_amount',\n",
    "    'mean texture': 'merchant_risk_score',\n",
    "    'mean perimeter': 'distance_from_home',\n",
    "    'mean area': 'transaction_frequency_last_24h',\n",
    "    'mean smoothness': 'customer_tenure_days',\n",
    "    'mean compactness': 'transaction_hour',\n",
    "    'mean concavity': 'transaction_day_of_week',\n",
    "    'mean concave points': 'similar_transactions_30d',\n",
    "    'mean symmetry': 'device_age_days',\n",
    "    'mean fractal dimension': 'ip_reputation_score'\n",
    "}\n",
    "\n",
    "# Create a subset with renamed columns for easier interpretation\n",
    "# We'll just use the first 10 features for this example\n",
    "X_subset = X.iloc[:, :10].copy()\n",
    "X_subset.columns = [column_mapping.get(col, col) for col in X_subset.columns]\n",
    "\n",
    "# Look at the first few rows\n",
    "X_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Explore correlations between features\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = X_subset.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Transaction Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare feature distributions between fraudulent and legitimate transactions\n",
    "# Let's look at a few key features\n",
    "key_features = ['transaction_amount', 'merchant_risk_score', 'distance_from_home', 'transaction_frequency_last_24h']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    sns.boxplot(x=y, y=X_subset[feature], ax=axes[i])\n",
    "    axes[i].set_title(f'{feature} by Transaction Type')\n",
    "    axes[i].set_xlabel('Transaction Type')\n",
    "    axes[i].set_xticklabels(['Legitimate', 'Fraud'])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Key Data Insights\n",
    "\n",
    "Based on our exploration, we can make several observations about our data:\n",
    "\n",
    "1. **Class Imbalance**: Our dataset has an imbalance between fraud and legitimate transactions, which is typical in fraud detection problems.\n",
    "\n",
    "2. **Feature Correlations**: Several features are highly correlated, which might affect some models.\n",
    "\n",
    "3. **Discriminative Features**: We can see clear differences in distributions between fraud and legitimate transactions for certain features.\n",
    "\n",
    "4. **Data Quality**: Fortunately, our dataset doesn't have missing values or duplicates, but in real scenarios, these are common issues we'd need to address.\n",
    "\n",
    "### 3.4 Data Preprocessing\n",
    "\n",
    "Now let's prepare our data for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} transactions ({y_train.mean()*100:.2f}% fraud)\")\n",
    "print(f\"Testing set: {X_test.shape[0]} transactions ({y_test.mean()*100:.2f}% fraud)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Scale the features \n",
    "# This is important for many ML algorithms, especially those based on distance calculations\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames for convenience\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "# Check the result of scaling\n",
    "print(\"After scaling:\")\n",
    "print(X_train_scaled.describe().loc[['mean', 'std']].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Development & Feature Engineering (15 min)\n",
    "\n",
    "Now that we have our data prepared, let's develop our model. We'll use LightGBM, which is a gradient boosting framework that uses tree-based learning algorithms and is known for its performance and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature Engineering\n",
    "\n",
    "Feature engineering is the process of creating new features from existing data to improve model performance. Let's create some new features that might be helpful for fraud detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Let's create some engineered features that might help with fraud detection\n",
    "# In a real scenario, we'd have more domain knowledge to guide this process\n",
    "\n",
    "# First, let's work with our original (unscaled) data\n",
    "# Create a function to add engineered features\n",
    "def add_engineered_features(df):\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Ratio features (using our renamed columns for clarity)\n",
    "    df_new['amount_to_frequency_ratio'] = df['mean radius'] / (df['mean area'] + 1)  # Add 1 to avoid division by zero\n",
    "    df_new['risk_distance_product'] = df['mean texture'] * df['mean perimeter']\n",
    "    \n",
    "    # Statistical transformations\n",
    "    df_new['log_amount'] = np.log1p(df['mean radius'])  # log(1+x) to handle zeros\n",
    "    \n",
    "    # For tree-based models, sometimes binning continuous variables helps\n",
    "    df_new['amount_bin'] = pd.qcut(df['mean radius'], q=5, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Polynomial features for specific pairs that might interact\n",
    "    df_new['texture_compactness_interaction'] = df['mean texture'] * df['mean compactness']\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Add engineered features to both training and testing sets\n",
    "X_train_engineered = add_engineered_features(X_train)\n",
    "X_test_engineered = add_engineered_features(X_test)\n",
    "\n",
    "# Display the new features\n",
    "new_features = ['amount_to_frequency_ratio', 'risk_distance_product', 'log_amount', \n",
    "                'amount_bin', 'texture_compactness_interaction']\n",
    "X_train_engineered[new_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Baseline Model\n",
    "\n",
    "Let's start with a simple baseline model to benchmark our performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a baseline LightGBM model\n",
    "baseline_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the original features\n",
    "baseline_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_baseline = baseline_model.predict(X_test_scaled)\n",
    "y_pred_proba_baseline = baseline_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate baseline performance\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba_baseline):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Enhanced Model with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a model with our engineered features\n",
    "enhanced_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the engineered features\n",
    "enhanced_model.fit(X_train_engineered, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_enhanced = enhanced_model.predict(X_test_engineered)\n",
    "y_pred_proba_enhanced = enhanced_model.predict_proba(X_test_engineered)[:, 1]\n",
    "\n",
    "# Evaluate enhanced performance\n",
    "print(\"Enhanced Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_enhanced):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_enhanced):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_enhanced):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_enhanced):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba_enhanced):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Hyperparameter Tuning\n",
    "\n",
    "Let's optimize our model further through hyperparameter tuning. This is a crucial step in developing a high-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define a hyperparameter grid\n",
    "# For the sake of time in this lab, we'll use a small grid\n",
    "# In a real scenario, you might explore many more combinations\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Create a model for grid search\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Set up grid search with cross-validation\n",
    "# We'll use recall as our scoring metric since it's our primary concern for fraud detection\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # Number of cross-validation folds\n",
    "    scoring='recall',  # Optimize for recall\n",
    "    n_jobs=-1,  # Use all available processors\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform grid search on the engineered features\n",
    "grid_search.fit(X_train_engineered, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best recall score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Create our final model with the best parameters\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the final model\n",
    "y_pred_final = final_model.predict(X_test_engineered)\n",
    "y_pred_proba_final = final_model.predict_proba(X_test_engineered)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Validation (10 min)\n",
    "\n",
    "Now let's thoroughly validate our model to ensure it meets our business requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a comprehensive evaluation report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=['Legitimate', 'Fraud'],\n",
    "            yticklabels=['Legitimate', 'Fraud'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_final)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba_final)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_final)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall, precision, color='blue', lw=2)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model Interpretability\n",
    "\n",
    "Understanding how our model makes decisions is crucial, especially for fraud detection where we need to explain why a transaction was flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature importance from the LightGBM model\n",
    "importance = final_model.feature_importances_\n",
    "feature_names = X_train_engineered.columns\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature
